# main.py
import asyncio
import json
import httpx
import re
import markdown
from bs4 import BeautifulSoup
from typing import List, Dict, Optional, Any, AsyncGenerator, Union

# 导入 AstrBot API
from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger, AstrBotConfig
from astrbot.api.provider import Provider, LLMResponse
import astrbot.api.message_components as Comp

from .search_engine_lib.models import SearchQuery, SearchResponse, SearchResultItem
from .search_engine_lib.base import BaseSearchEngine
from .search_engine_lib import initialize, list_engines, get_engine

from .core.constants import (
    PLUGIN_NAME,
    PLUGIN_VERSION,
    PLUGIN_DESCRIPTION,
    PLUGIN_AUTHOR,
    PLUGIN_REPO,
)

# HTML 报告模板，用于 html_render
HTML_REPORT_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Deep Research Report</title>
<style>
  body {{
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
    line-height: 1.6;
    color: #333;
    background-color: #f9f9f9;
    padding: 20px;
    max-width: 900px;
    margin: 20px auto;
    border: 1px solid #eee;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    border-radius: 8px;
  }}
  h1, h2, h3 {{ color: #0056b3; border-bottom: 1px solid #eee; padding-bottom: 5px;}}
  h1 {{ text-align: center; }}
  a {{ color: #007bff; text-decoration: none; }}
  a:hover {{ text-decoration: underline; }}
  pre {{ background-color: #eee; padding: 10px; border-radius: 4px; overflow-x: auto; }}
  code {{ background-color: #eee; padding: 2px 4px; border-radius: 3px; font-size: 0.9em;}}
  blockquote {{ border-left: 4px solid #ccc; padding-left: 15px; margin-left: 0; color: #555; font-style: italic;}}
   img {{ max-width: 100%; height: auto; }}
   ul, ol {{ padding-left: 25px; }}
   li {{ margin-bottom: 8px;}}
  .footer {{ margin-top: 30px; font-size: 0.8em; color: #777; text-align: center; border-top: 1px solid #eee; padding-top: 10px;}}
</style>
</head>
<body>
  <h1>深度研究报告</h1>
  {content}
  <div class="footer">Generated by AstrBot DeepResearch Plugin</div>
</body>
</html>
"""
# 内容最大长度限制，防止LLM上下文过长
MAX_CONTENT_LENGTH = 6000
# 最多筛选链接数
MAX_SELECTED_LINKS = 50
# 抓取超时
FETCH_TIMEOUT = 30.0


@register(
    PLUGIN_NAME,
    PLUGIN_AUTHOR,
    PLUGIN_DESCRIPTION,
    PLUGIN_VERSION,
    PLUGIN_REPO,
)
class DeepResearchPlugin(Star):
    """
    AstrBot 深度研究插件，实现查询处理、信息检索、内容处理、报告生成四个阶段。
    """

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.context = context
        self.config = config
        # 初始化异步 HTTP 客户端
        self.client = httpx.AsyncClient(
            timeout=FETCH_TIMEOUT, http2=True, follow_redirects=True, verify=False
        )
        self.search_engine_initialized = False
        self.available_engine_names: List[str] = []
        self.max_count: int = self.config.get("max_search_results_per_term", 6)
        self.max_terms: int = self.config.get("max_terms_to_search", 3)
        engine_config = self.config.get("engine_config", {})
        asyncio.create_task(self.initialize_engine(engine_config))
        logger.info("DeepResearchPlugin 初始化完成，HTTP 客户端已创建。")

    async def initialize_engine(self, engine_config):
        try:
            logger.info("DeepResearchPlugin: 正在使用配置初始化 search_engine_lib...")
            await initialize(engine_config)
            # 获取所有初始化成功的引擎列表
            self.available_engine_names = list_engines()

            # 检查是否有至少一个引擎可用
            if not self.available_engine_names:
                logger.error(
                    "DeepResearchPlugin: search_engine_lib 初始化完成，但未找到任何可用/已配置的引擎！请检查 engine_config。"
                )
                self.search_engine_initialized = False
            else:
                self.search_engine_initialized = True
                logger.info(
                    f"DeepResearchPlugin: search_engine_lib 初始化成功。将使用所有可用引擎: {self.available_engine_names}"
                )
        except Exception as e:
            logger.error(
                f"DeepResearchPlugin: 初始化 search_engine_lib 失败: {e}", exc_info=True
            )
            self.search_engine_initialized = False
            self.available_engine_names = []  # 确保失败时列表为空

    async def terminate(self):
        """插件终止时清理资源"""
        if hasattr(self, "client") and not self.client.is_closed:
            await self.client.aclose()
            logger.info("DeepResearchPlugin 资源已释放，HTTP 客户端已关闭。")

    # ------------------ LLM 调用辅助函数 ------------------
    async def _call_llm(
        self, provider: Provider, prompt: str, system_prompt: str = ""
    ) -> Optional[str]:
        """封装 LLM 调用，返回文本内容或 None"""
        try:
            # 调用 AstrBot 提供的 LLM 接口
            llm_response: LLMResponse = await provider.text_chat(
                prompt=prompt,
                session_id=None,
                contexts=[],
                image_urls=[],
                func_tool=None,
                system_prompt=system_prompt,
            )
            if (
                llm_response
                and llm_response.role == "assistant"
                and llm_response.completion_text
            ):
                # 尝试清理 JSON 字符串前后的 markdown 标记
                content = llm_response.completion_text.strip()
                content = re.sub(r"^```json\s*", "", content, flags=re.IGNORECASE)
                content = re.sub(r"\s*```$", "", content, flags=re.IGNORECASE)
                return content
            else:
                logger.warning(f"LLM 调用未返回有效助手消息: {llm_response}")
                return None
        except Exception as e:
            logger.error(f"调用 LLM 发生错误: {e}", exc_info=True)
            return None

    # ------------------ 阶段一：查询处理与扩展 (Query Processing) ------------------
    async def _stage1_query_processing(
        self, provider: Provider, query: str
    ) -> Optional[Dict[str, Any]]:
        """阶段一：使用 LLM 解析和扩展用户查询"""
        logger.info(f"阶段一：开始处理查询: {query}")
        system_prompt = """
        你是一个研究分析助手。你的任务是解析用户的原始问题，并将其分解和扩展，以便进行后续的信息检索。
        请严格按照以下 JSON 格式返回结果，不要包含任何额外的解释或文本。
        格式要求：
        {
          "original_question": "用户输入的原话",
          "sub_questions": ["将复杂问题拆解成的具体、易于检索的小问题列表"],
          "sub_topics": ["问题中包含的相关主题关键词列表"],
          "expansion_questions": ["基于原始问题，生成的有助于提供更全面答案的扩展性问题列表"],
          "search_queries": ["结合以上所有信息，生成 3-5 个用于搜索引擎的高质量搜索关键词短语列表"]
        }
        """
        response_text = await self._call_llm(provider, query, system_prompt)
        if not response_text:
            return None
        try:
            parsed_data = json.loads(response_text)
            # 将所有问题和搜索词合并，用于后续搜索
            all_search_terms = set()
            all_search_terms.add(query)
            all_search_terms.update(parsed_data.get("sub_questions", []))
            all_search_terms.update(parsed_data.get("sub_topics", []))
            all_search_terms.update(parsed_data.get("expansion_questions", []))
            all_search_terms.update(parsed_data.get("search_queries", []))
            parsed_data["all_search_terms"] = list(all_search_terms)
            logger.info(
                f"阶段一：查询解析成功。生成搜索词 {len(parsed_data['all_search_terms'])} 个。"
            )
            return parsed_data
        except json.JSONDecodeError:
            logger.error(f"阶段一：LLM 返回的 JSON 解析失败: {response_text[:200]}...")
            return None

    # ------------------ 阶段二：信息检索与筛选 (Information Retrieval & Filtering) ------------------
    # --- 新增: 单个搜索词查询辅助函数 ---
    async def _run_single_search(
        self, engine: BaseSearchEngine, term: str, count: int
    ) -> List[SearchResultItem]:
        """使用指定引擎和搜索词执行一次搜索，并处理异常"""
        if not term:
            return []
        logger.info(f"使用引擎 '{engine.name}' 搜索: '{term}' (count={count})")
        try:
            query_obj = SearchQuery(query=term, count=count)
            response: SearchResponse = await engine.search(query_obj)
            logger.debug(f"搜索 '{term}' 返回 {len(response.results)} 条结果。")
            return response.results
        except Exception as e:
            logger.error(
                f"使用引擎 '{engine.name}' 搜索 '{term}' 时发生错误: {e}", exc_info=True
            )
            return []

    # ----------------------------------
    async def _search_web(self, search_terms: List[str]) -> List[Dict[str, str]]:
        """
        阶段二：多源信息检索
        使用 search_engine_lib 中【所有可用引擎】并发搜索多个关键词，并合并、去重、格式化结果。
        """
        # 检查初始化状态和引擎列表
        if not self.search_engine_initialized or not self.available_engine_names:
            logger.error(
                "阶段二：search_engine_lib 未初始化、不可用，或没有找到任何可用引擎，无法执行搜索。"
            )
            return []

        if not search_terms:
            logger.warning("阶段二：没有提供搜索词。")
            return []
        # 获取所有可用的引擎实例
        engines: List[BaseSearchEngine] = []
        for name in self.available_engine_names:
            try:
                engine = get_engine(name)
                if engine:
                    engines.append(engine)
            except Exception as e:
                # 如果获取某个引擎失败，记录日志并跳过，继续使用其他引擎
                logger.warning(
                    f"阶段二：获取引擎 '{name}' 实例失败: {e}，将跳过此引擎。"
                )

        if not engines:
            logger.error("阶段二：无法获取任何有效的搜索引擎实例。")
            return []
        # 限制实际用于搜索的词条数量
        terms_to_search = [term for term in search_terms if term][: self.max_terms]

        engine_names_str = ", ".join([e.name for e in engines])
        logger.warning(
            f"阶段二：注意 API 消耗！准备使用 {len(engines)} 个引擎 ({engine_names_str}) 对 {len(terms_to_search)} 个词条进行并发搜索 (每个组合最多 {self.max_count} 条结果)..."
        )
        logger.info(
            f"阶段二：总计将执行最多 {len(engines) * len(terms_to_search)} 次搜索 API 调用。"
        )
        # 创建并行搜索任务列表: [engine1_term1, engine1_term2, ..., engine2_term1, engine2_term2, ...]
        tasks = []
        for engine in engines:  # 遍历每个引擎
            for term in terms_to_search:  # 遍历每个搜索词
                tasks.append(self._run_single_search(engine, term, self.max_count))

        # 并行执行
        all_results_nested: List[
            Union[List[SearchResultItem], Exception]
        ] = await asyncio.gather(*tasks, return_exceptions=True)
        # 展平结果列表，过滤掉异常，并转换格式 + 去重
        formatted_results: List[Dict[str, str]] = []
        seen_urls = set()
        total_items_found = 0

        for result_batch in all_results_nested:
            if isinstance(result_batch, list):
                total_items_found += len(result_batch)
                for item in result_batch:
                    url_str = str(item.link)
                    if url_str not in seen_urls:
                        formatted_results.append(
                            {
                                "title": item.title,
                                "url": url_str,
                                "snippet": item.snippet,
                            }
                        )
                        seen_urls.add(url_str)
            elif isinstance(result_batch, Exception):
                logger.warning(
                    f"一个搜索任务失败: {result_batch}"
                )  # 哪个引擎哪个词失败会在 _run_single_search 中记录

        logger.info(
            f"阶段二：所有搜索引擎共找到 {total_items_found} 条结果，合并去重后剩余 {len(formatted_results)} 条。"
        )
        return formatted_results

    async def _stage2_link_selection(
        self, provider: Provider, original_query: str, links: List[Dict[str, str]]
    ) -> List[str]:
        """阶段二：链接去重与 LLM 筛选"""
        # _search_web 已经去重过，这里可以简化或保留作为双重保险
        unique_links_dict = {link["url"]: link for link in links}
        unique_links = list(unique_links_dict.values())
        if not unique_links:
            return []
        logger.info(
            f"阶段二：准备从 {len(unique_links)} 个链接中进行 LLM 筛选，最多选择 {MAX_SELECTED_LINKS} 个..."
        )  # 更新日志
        link_descriptions = "\n".join(
            [
                f"- URL: {link['url']}\n  Title: {link['title']}\n  Snippet: {link.get('snippet', '')}"
                for link in unique_links
            ]
        )

        # 更新 prompt 中的 MAX_SELECTED_LINKS
        system_prompt = f"""
        你是一个研究分析助手。你的任务是从候选链接列表中，根据与原始问题的相关性，筛选出最相关、最有价值的最多 {MAX_SELECTED_LINKS} 个链接。
        原始问题： "{original_query}"

        请严格按照以下 JSON 列表格式返回结果，只包含选定链接的 URL 字符串，不要包含任何额外的解释或文本。
        格式要求：
        ["url1", "url2", "url3"]
        如果没有任何链接相关，返回空列表: []
        """
        prompt = f"请从以下链接中筛选出最相关的最多 {MAX_SELECTED_LINKS} 个：\n\n{link_descriptions}"
        response_text = await self._call_llm(provider, prompt, system_prompt)
        if not response_text:
            return []
        try:
            selected_urls = json.loads(response_text)
            if not isinstance(selected_urls, list):
                raise TypeError("LLM did not return a list")
            final_list = [
                str(url) for url in selected_urls if str(url) in unique_links_dict
            ][:MAX_SELECTED_LINKS]  # 使用更新后的 MAX_SELECTED_LINKS
            logger.info(f"阶段二：LLM 筛选完成，选定 {len(final_list)} 个链接。")
            return final_list
        except (json.JSONDecodeError, TypeError) as e:
            logger.error(
                f"阶段二：LLM 链接筛选结果 JSON 解析失败 ({e}): {response_text[:200]}..."
            )
            return list(unique_links_dict.keys())[:MAX_SELECTED_LINKS]

    # ------------------ 阶段三：内容处理与分析 (Content Processing & Analysis) ------------------

    async def _fetch_and_parse_content(self, url: str) -> Optional[str]:
        """抓取单个URL内容并提取清洗后的文本"""
        logger.info(f"阶段三：正在抓取 URL: {url}")
        try:
            async with self.client as client:
                response = await client.get(
                    url, headers={"User-Agent": "Mozilla/5.0 AstrBot/1.0"}
                )
                response.raise_for_status()  # 检查 HTTP 错误

                # 使用 BeautifulSoup 提取文本
                soup = BeautifulSoup(response.content, "lxml")
                # 移除 script 和 style 标签
                for script in soup(["script", "style"]):
                    script.decompose()

                text = soup.get_text()
                # 清洗文本：移除多余空白字符
                text = re.sub(r"\s+", " ", text).strip()
                # 截断过长文本
                logger.info(f"阶段三：URL {url} 抓取完成，清洗后长度: {len(text)}")
                return text[:MAX_CONTENT_LENGTH]
        except httpx.HTTPStatusError as e:
            logger.warning(
                f"抓取 URL {url} 失败，HTTP 状态码: {e.response.status_code}"
            )
        except httpx.RequestError as e:
            logger.warning(f"抓取 URL {url} 失败，请求错误: {e}")
        except Exception as e:
            logger.error(f"抓取或解析 URL {url} 发生未知错误: {e}", exc_info=True)
        return None

    async def _summarize_content(
        self, provider: Provider, query: str, url: str, content: str
    ) -> Optional[str]:
        """使用 LLM 总结单个文档内容"""
        logger.info(f"阶段三：正在总结 URL {url} 的内容...")
        system_prompt = f"""
        你是一个研究分析助手。请基于以下提供的文本内容，总结出与原始查询：“{query}” 高度相关的关键信息。
        总结应清晰、简洁，突出要点。忽略广告、导航等无关内容。
        请直接返回总结文本，不要包含任何额外的解释、标题或问候语。
        """
        prompt = f"请根据查询 “{query}” 总结以下文本：\n\n---\n{content}\n---"
        summary = await self._call_llm(provider, prompt, system_prompt)
        if summary:
            logger.info(f"阶段三：URL {url} 总结完成。")
        else:
            logger.warning(f"阶段三：URL {url} 总结失败。")
        return summary

    async def _process_one_link(
        self, provider: Provider, query: str, url: str
    ) -> Optional[Dict[str, str]]:
        """处理单个链接：抓取 -> 总结"""
        content = await self._fetch_and_parse_content(url)
        if content and len(content) > 100:  # 忽略内容过少的页面
            summary = await self._summarize_content(provider, query, url, content)
            if summary:
                return {"url": url, "summary": summary}
        return None

    async def _stage3_content_processing(
        self, provider: Provider, query: str, selected_links: List[str]
    ) -> List[Dict[str, str]]:
        """阶段三：并行抓取内容并生成摘要"""
        logger.info("阶段三：开始并行抓取和总结内容...")
        # 创建并行任务
        tasks = [self._process_one_link(provider, query, url) for url in selected_links]
        # 并行执行，允许部分失败
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # 过滤掉失败或无效的结果
        summaries = [
            res
            for res in results
            if isinstance(res, dict) and res is not None and "summary" in res
        ]
        logger.info(
            f"阶段三：成功处理并总结了 {len(summaries)} / {len(selected_links)} 个链接。"
        )
        return summaries

    async def _stage3_aggregation(
        self,
        provider: Provider,
        query: str,
        expansion_questions: List[str],
        summaries: List[Dict[str, str]],
    ) -> Optional[str]:
        """阶段三：LLM 聚合分析所有摘要，生成 Markdown 报告"""
        logger.info("阶段三：开始聚合分析所有摘要...")
        if not summaries:
            return "未能从任何来源获取有效摘要，无法生成报告。"
        # 准备 LLM 输入
        summaries_input = "\n\n".join(
            [f"### 来源: {item['url']}\n{item['summary']}\n---" for item in summaries]
        )
        expansion_q_str = (
            "\n".join([f"- {q}" for q in expansion_questions])
            if expansion_questions
            else "无"
        )
        system_prompt = f"""
        你是一个高级研究分析师。你的任务是综合来自多个来源的摘要信息，生成一份结构清晰、内容连贯、逻辑严密的深度研究报告（Markdown 格式）。

        原始查询: "{query}"

        需要额外考虑和回答的扩展问题:
        {expansion_q_str}
        报告要求：
        1. 格式：使用标准的 Markdown 语法。
        2. 结构：应包含标题、引言、主体段落（可以按主题或扩展问题分节）、结论。
        3. 内容：综合所有来源的信息，对比不同观点（如果存在），整合信息，构建逻辑。
        4. 引用：在引用了某个来源信息的句子或段落末尾，明确标注来源，格式为 ` [来源: URL]`。
        5. 目标：全面、深入地回答原始查询及扩展问题。
        6. 输出：直接输出 Markdown 报告正文，不要包含任何额外的解释或问候语。
        """
        prompt = f"请根据以下来自不同来源的摘要信息，生成一份关于 “{query}” 的深度研究报告：\n\n{summaries_input}"
        report_markdown = await self._call_llm(provider, prompt, system_prompt)
        if report_markdown:
            logger.info("阶段三：聚合分析完成，Markdown 报告已生成。")
        else:
            logger.warning("阶段三：聚合分析失败。")
        return report_markdown

    # ------------------ 阶段四：报告生成与交付 (Report Generation & Delivery) ------------------
    async def _stage4_report_generation(self, markdown_text: str) -> Optional[str]:
        """阶段四：将 Markdown 报告渲染为图片 URL"""
        logger.info("阶段四：开始将 Markdown 渲染为图片...")
        try:
            # 1. Markdown 转 HTML
            html_body = markdown.markdown(
                markdown_text, extensions=["extra", "codehilite", "tables", "toc"]
            )
            # 2. 填充模板
            full_html = HTML_REPORT_TEMPLATE.format(content=html_body)
            # 3. 使用 AstrBot 的 html_render 渲染图片
            # html_render 是 Star 基类的方法
            image_url = await self.html_render(full_html, {}, return_url=True)
            logger.info("阶段四：图片报告渲染成功。")
            return image_url
        except Exception as e:
            logger.error(f"阶段四：Markdown 转 HTML 或渲染图片失败: {e}", exc_info=True)
            return None

    # ------------------ 主流程控制 ------------------

    async def _run_research_pipeline(
        self, event: AstrMessageEvent, query: str
    ) -> AsyncGenerator[MessageEventResult, None]:
        """执行完整的研究流程管线，使用异步生成器发送中间状态和最终结果"""
        # 检查 LLM
        provider = self.context.get_using_provider()
        if not provider:
            yield event.plain_result(
                "❌ 错误：未配置或启用大语言模型(LLM)，无法执行研究。"
            )
            return

        start_time = asyncio.get_running_loop().time()
        yield event.plain_result(
            f"🔎 收到研究请求: '{query}'\n⏳ 开始阶段一：查询处理与扩展..."
        )

        try:
            # 阶段一
            parsed_query = await self._stage1_query_processing(provider, query)
            if not parsed_query or not parsed_query.get("all_search_terms"):
                yield event.plain_result("❌ 阶段一失败：LLM未能有效解析查询。")
                return
            yield event.plain_result(
                "✅ 阶段一完成。\n⏳ 开始阶段二：信息检索与筛选..."
            )
            # 阶段二
            search_terms = parsed_query.get("search_queries", []) or parsed_query.get(
                "all_search_terms", []
            )
            initial_links = await self._search_web(search_terms)
            if not initial_links:
                yield event.plain_result(
                    "⚠️ 阶段二警告：网络搜索未返回任何初始结果（或搜索功能未实现）。"
                )
                # 如果搜索失败，尝试直接让LLM回答
                yield event.plain_result("⚠️ 尝试让LLM根据自身知识直接生成报告...")
                direct_summary = await self._summarize_content(
                    provider,
                    query,
                    "LLM Knowledge Base",
                    "请基于你自身的知识库，生成一份关于此主题的报告。",
                )
                if direct_summary:
                    summaries = [
                        {"url": "LLM Knowledge Base", "summary": direct_summary}
                    ]
                    selected_links = ["LLM Knowledge Base"]
                else:
                    yield event.plain_result(
                        "❌ 阶段二失败：搜索和LLM自身知识均无法提供信息。"
                    )
                    return
            else:
                yield event.plain_result(
                    f"ℹ️ 搜索到 {len(initial_links)} 个初始链接，开始筛选..."
                )
                selected_links = await self._stage2_link_selection(
                    provider, query, initial_links
                )
                if not selected_links:
                    yield event.plain_result(
                        "❌ 阶段二失败：LLM未能从结果中筛选出相关链接。"
                    )
                    return
                yield event.plain_result(
                    f"✅ 阶段二完成。筛选出 {len(selected_links)} 个链接。\n⏳ 开始阶段三：内容处理与分析..."
                )
                # 阶段三 - 处理
                summaries = await self._stage3_content_processing(
                    provider, query, selected_links
                )
                if not summaries:
                    yield event.plain_result(
                        "❌ 阶段三失败：未能从任何选定链接抓取或总结有效内容。"
                    )
                    return
                yield event.plain_result(
                    f"ℹ️ 已抓取并总结 {len(summaries)} 篇内容。开始聚合分析..."
                )

            # 阶段三 - 聚合
            aggregated_markdown = await self._stage3_aggregation(
                provider, query, parsed_query.get("expansion_questions", []), summaries
            )
            if not aggregated_markdown:
                yield event.plain_result("❌ 阶段三失败：LLM内容聚合分析失败。")
                return
            yield event.plain_result(
                "✅ 阶段三完成。\n⏳ 开始阶段四：报告生成与渲染..."
            )
            # 阶段四
            report_image_url = await self._stage4_report_generation(aggregated_markdown)

            end_time = asyncio.get_running_loop().time()
            duration = round(end_time - start_time, 2)
            # 最终输出
            status_msg = f"✅ 深度研究完成！总耗时: {duration} 秒。"
            if report_image_url:
                # 使用消息链发送文本和图片
                yield event.chain_result(
                    [
                        Comp.Plain(text=status_msg + "\n为您生成了图片报告："),
                        Comp.Image.fromURL(report_image_url),
                        # Comp.Plain(text="\n\n--- Markdown 原文 ---\n" + aggregated_markdown) # 可选：附带Markdown原文
                    ]
                )
            else:
                # 图片生成失败，回退到纯文本 Markdown
                yield event.plain_result(
                    status_msg
                    + "\n⚠️ 图片报告生成失败，以下为 Markdown 文本报告：\n---\n"
                    + aggregated_markdown
                )
        except asyncio.TimeoutError:
            yield event.plain_result("❌ 研究过程超时。")
            logger.error("Pipeline Timeout", exc_info=True)
        except Exception as e:
            yield event.plain_result(
                f"❌ 研究过程中发生未知错误: {type(e).__name__} - {e}"
            )
            logger.error(f"Pipeline error for query '{query}': {e}", exc_info=True)

    @filter.command("deepresearch", alias={"研究", "深度研究"})
    async def handle_research_command(self, event: AstrMessageEvent, query: str = ""):
        """
        指令: /deepresearch <查询内容>
        对指定内容进行多阶段深度研究并生成报告。
        """
        if not query:
            yield event.plain_result(
                "请输入要研究的内容。例如: /deepresearch 人工智能的未来发展趋势"
            )
            return

        # 使用异步生成器模式，逐个 yield 消息
        async for message_result in self._run_research_pipeline(event, query):
            yield message_result
        event.stop_event()  # 停止事件传播，防止LLM再次默认回复
