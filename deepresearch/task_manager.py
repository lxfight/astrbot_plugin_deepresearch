import asyncio
import uuid
from typing import Dict, Optional, List, Any
from datetime import datetime

from astrbot.api import star, logger, AstrBotConfig
from astrbot.api.event import AstrMessageEvent, MessageEventResult
from astrbot.api.message_components import Plain, Image

# å¯¼å…¥æ‰€æœ‰éœ€è¦åè°ƒçš„æ¨¡å—
from .data_models import (
    UserResearchQuery,
    QueryAnalysisResult,
    RetrievedItem,
    RetrievalPhaseOutput,
    ProcessedContent,
    SourceInsight,
    SubTopicSynthesis,
    ReportSection,
    ResearchReport,
    DeepResearchTask,
)
from .llm_modules.query_parser import QueryParser
from .llm_modules.content_selector import ContentSelector
from .llm_modules.document_processor import DocumentProcessor
from .llm_modules.report_generator import ReportGenerator
from .retrieval.retriever_factory import RetrieverFactory

# from deepresearch.retrieval.custom_db_adapter import CustomDBAdapter # å¦‚æœæœ‰çš„è¯
from .content_processing.html_extractor import HTMLExtractor
from .output_formatter.report_formatter import (
    ReportFormatter,
)  # åŒ…å«mdè½¬htmlå’Œhtmlæ¸²æŸ“å›¾ç‰‡
from .output_formatter.file_manager import FileManager


class TaskManager:
    """
    æ·±åº¦ç ”ç©¶ä»»åŠ¡ç®¡ç†å™¨ï¼Œè´Ÿè´£ä»»åŠ¡çš„å¯åŠ¨ã€çŠ¶æ€ç®¡ç†ã€è¿›åº¦é€šçŸ¥å’Œæ¸…ç†ã€‚
    å®ƒæ˜¯ DeepResearch æ’ä»¶çš„æ ¸å¿ƒç¼–æ’å™¨ã€‚
    """

    def __init__(self, context: star.Context, config: AstrBotConfig):
        self.context = context
        self.config = config
        self.logger = logger
        self.active_tasks: Dict[str, DeepResearchTask] = {}  # å­˜å‚¨æ‰€æœ‰æ´»è·ƒä»»åŠ¡
        self.task_futures: Dict[
            str, asyncio.Task
        ] = {}  # å­˜å‚¨ä»»åŠ¡å¯¹åº”çš„ asyncio.Task å¯¹è±¡

        # åˆå§‹åŒ–å„ä¸ªä¸šåŠ¡æ¨¡å—å®ä¾‹
        self.query_parser = QueryParser(context, config)
        self.content_selector = ContentSelector(context, config)
        self.document_processor = DocumentProcessor(context, config)
        self.report_generator = ReportGenerator(context, config)

        self.retriever_factory = RetrieverFactory(context, config)

        self.html_extractor = HTMLExtractor(context, config)
        self.report_formatter = ReportFormatter(context, config)
        self.file_manager = FileManager(context, config)

        self.logger.info("TaskManager åˆå§‹åŒ–å®Œæˆï¼Œæ‰€æœ‰å­æ¨¡å—å·²è½½å…¥ã€‚")

    async def start_research_task(
        self, user_query: UserResearchQuery, event: AstrMessageEvent
    ) -> str:
        """
        å¯åŠ¨ä¸€ä¸ªæ–°çš„æ·±åº¦ç ”ç©¶ä»»åŠ¡ã€‚
        """
        task_id = str(uuid.uuid4())
        task = DeepResearchTask(task_id=task_id, user_query=user_query)
        self.active_tasks[task_id] = task

        # å°†ç ”ç©¶æµç¨‹ä½œä¸ºç‹¬ç«‹çš„ asyncio ä»»åŠ¡è¿è¡Œï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        task_coro = self._run_research_pipeline(task, event)
        task_future = asyncio.create_task(task_coro)
        self.task_futures[task_id] = task_future

        self.logger.info(f"æ·±åº¦ç ”ç©¶ä»»åŠ¡ {task_id} å·²å¯åŠ¨ã€‚")
        return task_id

    async def _run_research_pipeline(
        self, task: DeepResearchTask, event: AstrMessageEvent
    ):
        """
        æ‰§è¡Œå®Œæ•´çš„æ·±åº¦ç ”ç©¶æµç¨‹ã€‚
        è¿™æ˜¯ä¸€ä¸ªé•¿è¿è¡Œçš„åç¨‹ï¼Œä¼šåœ¨åå°æ‰§è¡Œæ‰€æœ‰æ­¥éª¤ã€‚
        """
        try:
            # é˜¶æ®µ1: LLMè§£æç”¨æˆ·é—®é¢˜
            task.update_status("analyzing_query")
            await event.send(
                f"ğŸ¤– ä»»åŠ¡ `{task.task_id[:8]}` å¯åŠ¨ï¼šæ­£åœ¨è§£ææ‚¨çš„ç ”ç©¶é—®é¢˜..."
            )
            query_analysis_result = await self.query_parser.parse_query(task.user_query)
            task.query_analysis_result = query_analysis_result
            await event.send(
                f"âœ… ä»»åŠ¡ `{task.task_id[:8]}`ï¼šé—®é¢˜è§£æå®Œæˆã€‚è¯†åˆ«å‡º {len(query_analysis_result.identified_sub_topics)} ä¸ªå­ä¸»é¢˜ã€‚"
            )

            # é˜¶æ®µ2: å¤šæºä¿¡æ¯æ£€ç´¢ - ä½¿ç”¨å·¥å‚æ¨¡å¼
            task.update_status("retrieving_sources")
            await event.send(
                f"ğŸ” ä»»åŠ¡ `{task.task_id[:8]}`ï¼šæ­£åœ¨ä»å¤šæºï¼ˆç½‘ç»œã€æ–°é—»ã€å­¦æœ¯ç­‰ï¼‰æ£€ç´¢ä¿¡æ¯..."
            )
            all_retrieved_items: List[RetrievedItem] = []

            # è·å–æ‰€æœ‰å¯ç”¨çš„æ£€ç´¢å™¨
            available_retrievers = self.retriever_factory.get_available_retrievers()
            self.logger.info(f"å¯ç”¨æ£€ç´¢å™¨ç±»å‹ï¼š{list(available_retrievers.keys())}")

            # ä»é…ç½®ä¸­æå–æœç´¢é…ç½®
            search_config = self._extract_complete_search_config()

            for (
                source_type,
                queries,
            ) in query_analysis_result.planned_search_queries.items():
                if not queries:
                    continue  # æ²¡æœ‰ä¸ºè¯¥æ¥æºç”ŸæˆæŸ¥è¯¢è¯

                retriever = available_retrievers.get(source_type)
                if retriever:
                    self.logger.info(
                        f"ä½¿ç”¨æ£€ç´¢å™¨ '{retriever.__class__.__name__}' è¿›è¡Œ '{source_type}' æœç´¢ã€‚"
                    )
                    for query in queries:
                        self.logger.debug(f"æ‰§è¡Œ '{source_type}' æœç´¢: '{query}'")
                        try:
                            results = await retriever.search(query, search_config)
                            # ç¡®ä¿ç»“æœç¬¦åˆRetrievedItemæ¨¡å‹
                            for result in results:
                                if not hasattr(result, "source") or not result.source:
                                    result.source = source_type
                                if not hasattr(result, "metadata"):
                                    result.metadata = {}
                                # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯åˆ°å…ƒæ•°æ®
                                result.metadata["original_query"] = query
                                result.metadata["retriever_type"] = (
                                    retriever.__class__.__name__
                                )

                            all_retrieved_items.extend(results)
                        except Exception as e:
                            self.logger.error(
                                f"æœç´¢'{query}'æ—¶å‡ºé”™: {e}", exc_info=True
                            )
                else:
                    self.logger.warning(
                        f"æ£€ç´¢å™¨ç±»å‹ '{source_type}' æœªé…ç½®æˆ–ä¸å¯ç”¨ï¼Œè·³è¿‡è¯¥æ¥æºçš„æœç´¢ã€‚"
                    )

            retrieval_output = RetrievalPhaseOutput(
                query_analysis=query_analysis_result,
                all_retrieved_items=all_retrieved_items,
            )
            retrieval_output.perform_deduplication()  # URLå»é‡
            task.retrieval_output = retrieval_output
            await event.send(
                f"âœ¨ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šä¿¡æ¯æ£€ç´¢å®Œæˆï¼Œå…±å‘ç° {len(retrieval_output.unique_retrieved_items)} æ¡ä¸é‡å¤çš„æ½œåœ¨ç›¸å…³é“¾æ¥ã€‚"
            )

            # é˜¶æ®µ3: LLMç­›é€‰ä¸å†…å®¹æå–
            task.update_status("processing_content")
            await event.send(
                f"ğŸ“„ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šæ­£åœ¨ç­›é€‰ç›¸å…³å†…å®¹å¹¶æå–æ–‡æœ¬..."
            )
            processed_contents: List[ProcessedContent] = []
            relevant_contents: List[ProcessedContent] = []

            # ä¼˜åŒ–ï¼šå¹¶è¡ŒæŠ“å–
            fetch_tasks = [
                self.html_extractor.extract_text(item.url)
                for item in retrieval_output.unique_retrieved_items
            ]
            extracted_texts = await asyncio.gather(*fetch_tasks, return_exceptions=True)

            for i, item in enumerate(retrieval_output.unique_retrieved_items):
                extracted_text = extracted_texts[i]
                if isinstance(extracted_text, Exception):
                    self.logger.warning(
                        f"æŠ“å–æˆ–æå– '{item.url}' å¤±è´¥: {extracted_text}"
                    )
                    processed_item = ProcessedContent(
                        retrieved_item=item,
                        processing_error=str(extracted_text),
                        fetch_time=datetime.now(),
                    )
                else:
                    processed_item = ProcessedContent(
                        retrieved_item=item,
                        extracted_text=extracted_text,
                        fetch_time=datetime.now(),
                    )
                processed_contents.append(processed_item)

                # ä»…å¯¹æˆåŠŸæå–åˆ°æ–‡æœ¬çš„é¡¹è¿›è¡Œç›¸å…³æ€§ç­›é€‰
                if processed_item.extracted_text:
                    is_relevant, score = await self.content_selector.check_relevance(
                        query_analysis_result, item, processed_item.extracted_text
                    )
                    processed_item.is_relevant = is_relevant
                    processed_item.relevance_score = score
                    if is_relevant:
                        relevant_contents.append(processed_item)
                else:
                    processed_item.is_relevant = False  # æ— æ³•æå–å†…å®¹é»˜è®¤ä¸ç›¸å…³

            task.processed_contents = processed_contents
            task.relevant_contents = relevant_contents
            await event.send(
                f"ğŸ“ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šå†…å®¹ç­›é€‰ä¸æå–å®Œæˆï¼Œè·å¾— {len(relevant_contents)} ç¯‡ç›¸å…³æ–‡æ¡£ã€‚"
            )

            # é˜¶æ®µ4: LLMæ–‡æ¡£å¤„ç†ä¸å†…å®¹æ€»ç»“
            task.update_status("synthesizing_insights")
            await event.send(
                f"ğŸ’¡ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šæ­£åœ¨å¯¹æ–‡æ¡£è¿›è¡Œæ·±åº¦åˆ†æä¸æ€»ç»“..."
            )

            # å¹¶è¡Œå¤„ç†æ¯ä¸ªç›¸å…³æ–‡æ¡£çš„æ´å¯Ÿæå–
            insight_tasks = []
            for doc in relevant_contents:
                insight_tasks.append(
                    self.document_processor.process_and_summarize_document(
                        query_analysis_result, doc
                    )
                )

            # å±•å¹³åˆ—è¡¨çš„åˆ—è¡¨
            list_of_lists_of_insights = await asyncio.gather(*insight_tasks)
            source_insights: List[SourceInsight] = [
                insight for sublist in list_of_lists_of_insights for insight in sublist
            ]
            task.source_insights = source_insights

            # æŒ‰å­ä¸»é¢˜èšåˆå’Œç»¼åˆ
            sub_topic_syntheses: List[
                SubTopicSynthesis
            ] = await self.document_processor.synthesize_by_sub_topic(
                query_analysis_result, source_insights
            )
            task.sub_topic_syntheses = sub_topic_syntheses
            await event.send(
                f"ğŸ“Š ä»»åŠ¡ `{task.task_id[:8]}`ï¼šæ–‡æ¡£åˆ†æä¸å­ä¸»é¢˜æ€»ç»“å®Œæˆã€‚"
            )

            # é˜¶æ®µ5: LLMèšåˆåˆ†æä¸æŠ¥å‘Šç”Ÿæˆ
            task.update_status("generating_report")
            await event.send(f"âœï¸ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šæ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š...")
            final_report = await self.report_generator.generate_full_report(
                task.user_query, query_analysis_result, sub_topic_syntheses
            )
            task.final_report = final_report
            await event.send(f"ğŸ‰ ä»»åŠ¡ `{task.task_id[:8]}`ï¼šç ”ç©¶æŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆï¼")

            # é˜¶æ®µ6: è¾“å‡ºæ ¼å¼åŒ–ä¸äº¤ä»˜
            task.update_status("completed")
            await event.send(
                f"å®Œæˆï¼ä»»åŠ¡ `{task.task_id[:8]}` çš„æŠ¥å‘Šæ ‡é¢˜ä¸ºï¼š`{final_report.main_title}`ã€‚"
            )

            # é»˜è®¤è¾“å‡ºæ ¼å¼
            default_format = self.config.get("output_config", {}).get(
                "default_output_format", "md"
            )
            await self._send_report_output(
                event, final_report, task.task_id, default_format
            )

        except Exception as e:
            error_message = f"ç ”ç©¶ä»»åŠ¡ `{task.task_id[:8]}` æ‰§è¡Œå¤±è´¥: {e}"
            self.logger.error(error_message, exc_info=True)
            task.update_status("failed", str(e))
            await event.send(f"ğŸ˜­ {error_message}")
        finally:
            # æ¸…ç†ä»»åŠ¡ï¼Œä½†ä¿æŒ active_tasks ä¸­çš„è®°å½•ï¼Œç›´åˆ°ç”¨æˆ·ä¸»åŠ¨æ¸…ç†æˆ–è¿‡æœŸ
            # self.cleanup_task(task.task_id) # è€ƒè™‘æ˜¯å¦åœ¨å®Œæˆåç«‹å³æ¸…ç†futureï¼Œä½†ä¿ç•™æ•°æ®
            pass  # æš‚æ—¶ä¸ç«‹å³æ¸…ç†ï¼Œè®©ç”¨æˆ·å¯ä»¥æŸ¥è¯¢çŠ¶æ€å’Œç»“æœ

    async def _send_report_output(
        self,
        event: AstrMessageEvent,
        report: ResearchReport,
        task_id: str,
        format_type: str,
    ):
        """æ ¹æ®æŒ‡å®šæ ¼å¼å‘é€æŠ¥å‘Šè¾“å‡ºã€‚"""
        try:
            if format_type.lower() == "md":
                md_content = report.get_full_markdown_content()
                # è€ƒè™‘æŠ¥å‘Šè¿‡é•¿æ—¶ä¿å­˜ä¸ºæ–‡ä»¶å¹¶æä¾›é“¾æ¥
                if len(md_content) > 2000:  # å‡è®¾æ¶ˆæ¯æœ€å¤§é•¿åº¦
                    file_info = await self.file_manager.save_text_as_file(
                        md_content, f"deep_research_report_{task_id[:8]}.md", "md"
                    )
                    await event.send(
                        f"ğŸ“„ æŠ¥å‘ŠMarkdownæ–‡ä»¶å·²ç”Ÿæˆï¼š{file_info['file_url']}"
                    )
                else:
                    await event.send(f"```markdown\n{md_content}\n```")
            elif format_type.lower() == "html":
                html_content = await self.report_formatter.format_report(report, "html")
                file_info = await self.file_manager.save_text_as_file(
                    html_content, f"deep_research_report_{task_id[:8]}.html", "html"
                )
                await event.send(f"ğŸŒ æŠ¥å‘ŠHTMLç½‘é¡µå·²ç”Ÿæˆï¼š{file_info['file_url']}")
            elif format_type.lower() == "image":
                image_url = await self.report_formatter.format_report(report, "image")
                await event.send("ğŸ–¼ï¸ æŠ¥å‘Šå›¾ç‰‡å·²ç”Ÿæˆï¼š")
                await event.send(MessageEventResult(chain=[Image.fromURL(image_url)]))
            else:
                await event.send(f"âŒ æš‚ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼ï¼š`{format_type}`")
        except Exception as e:
            self.logger.error(
                f"å‘é€æŠ¥å‘Šè¾“å‡ºå¤±è´¥ (ä»»åŠ¡ {task_id}, æ ¼å¼ {format_type}): {e}",
                exc_info=True,
            )
            await event.send(f"âŒ å‘é€æŠ¥å‘Šå¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚é”™è¯¯ï¼š{e}")

    def get_task_status(self, task_id: str) -> Optional[DeepResearchTask]:
        """æ ¹æ®ä»»åŠ¡IDè·å–ä»»åŠ¡çŠ¶æ€ã€‚"""
        return self.active_tasks.get(task_id)

    def cleanup_task(self, task_id: str):
        """
        æ¸…ç†å·²å®Œæˆæˆ–å¤±è´¥çš„ä»»åŠ¡ã€‚
        å¯ä»¥ç”¨äºé‡Šæ”¾èµ„æºæˆ–ä»æ´»è·ƒä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤ã€‚
        """
        if task_id in self.task_futures:
            self.task_futures[task_id].cancel()
            del self.task_futures[task_id]
        if task_id in self.active_tasks:
            # æ ¹æ®éœ€æ±‚ï¼Œå¯ä»¥é€‰æ‹©ä¿ç•™å·²å®Œæˆ/å¤±è´¥çš„ä»»åŠ¡æ•°æ®ä¸€æ®µæ—¶é—´ï¼Œæˆ–è€…ç«‹å³åˆ é™¤
            self.logger.info(f"ä»»åŠ¡ {task_id} å·²ä»æ´»è·ƒä»»åŠ¡åˆ—è¡¨ä¸­æ¸…ç†ã€‚")
            # del self.active_tasks[task_id] # æš‚æ—¶ä¸åˆ é™¤ï¼Œæ–¹ä¾¿ç”¨æˆ·æŸ¥è¯¢å†å²çŠ¶æ€

    def _extract_complete_search_config(self) -> Dict[str, Any]:
        """æå–å®Œæ•´çš„æœç´¢é…ç½®"""
        search_config = {}

        # æå–å„ç§æœç´¢å¼•æ“çš„é…ç½®
        config_sections = [
            "google_search",
            "bing_search",
            "serper_search",
            "baidu_search",
            "news_search",
            "academic_search",
        ]

        for section in config_sections:
            section_config = self.config.get(section, {})
            for key, value in section_config.items():
                # æ„å»ºç»Ÿä¸€çš„é…ç½®é”®å
                if section == "google_search":
                    if key == "cse_api_key":
                        search_config["google_cse_api_key"] = value
                    elif key == "cse_cx":
                        search_config["google_cse_cx"] = value
                elif section == "bing_search":
                    if key == "api_key":
                        search_config["bing_api_key"] = value
                    elif key == "endpoint":
                        search_config["bing_endpoint"] = value
                elif section == "serper_search":
                    if key == "api_key":
                        search_config["serper_api_key"] = value
                elif section == "baidu_search":
                    if key == "api_key":
                        search_config["baidu_api_key"] = value
                    elif key == "secret_key":
                        search_config["baidu_secret_key"] = value
                elif section == "news_search":
                    if key == "news_api_key":
                        search_config["news_api_key"] = value
                elif section == "academic_search":
                    if key == "semantic_scholar_api_key":
                        search_config["academic_search_api_key"] = value

        # ä¿æŒå‘åå…¼å®¹æ€§
        old_search_config = self.config.get("search_config", {})
        search_config.update(old_search_config)

        return search_config
